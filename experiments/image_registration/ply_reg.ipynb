{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-05-04T10:00:26.078202Z",
     "end_time": "2023-05-04T10:00:26.936536Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "def draw_registration_result(source, target, transformation):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "    target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    source_temp.transform(transformation)\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp])\n",
    "\n",
    "\n",
    "def execute_global_registration(\n",
    "        source_down,\n",
    "        target_down,\n",
    "        source_fpfh,\n",
    "        target_fpfh,\n",
    "        voxel_size\n",
    "):\n",
    "    distance_threshold = voxel_size * 1.5\n",
    "    result = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(\n",
    "        source=source_down,\n",
    "        target=target_down,\n",
    "        source_feature=source_fpfh,\n",
    "        target_feature=target_fpfh,\n",
    "        mutual_filter=True,\n",
    "        max_correspondence_distance=distance_threshold,\n",
    "        estimation_method=o3d.pipelines.registration.TransformationEstimationPointToPoint(False),\n",
    "        # estimation_method=o3d.pipelines.registration.TransformationEstimationPointToPlane(),\n",
    "        ransac_n=3,\n",
    "        checkers=[\n",
    "            o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(0.9),\n",
    "            o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(distance_threshold)\n",
    "        ],\n",
    "        criteria=o3d.pipelines.registration.RANSACConvergenceCriteria(200000, 0.99999)\n",
    "    )\n",
    "    return result\n",
    "\n",
    "\n",
    "def preprocess_point_cloud(pcd, voxel_size):\n",
    "    # pcd_down = pcd.voxel_down_sample(voxel_size)\n",
    "    pcd_down = pcd\n",
    "    radius_normal = voxel_size * 2\n",
    "    pcd_down.estimate_normals(o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=30))\n",
    "\n",
    "    radius_feature = voxel_size * 5\n",
    "    pcd_fpfh = o3d.pipelines.registration.compute_fpfh_feature(\n",
    "        pcd_down,\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_feature, max_nn=100))\n",
    "    return pcd_down, pcd_fpfh\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-04T10:57:24.414923Z",
     "end_time": "2023-05-04T10:57:24.430914Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "# ply_source = \"D:/sfm_dense/street_1_0_real_time/target.ply\"\n",
    "ply_source = \"D:/sfm_dense/street_2_0/dense/0/fused_filtered_down_aligned.ply\"\n",
    "\n",
    "# ply_target = \"D:/sfm_dense/street_1_0_query/dense/0/fused.ply\"\n",
    "# ply_target = \"D:/sfm_dense/street_1_0_query/query.sparse.ply\"\n",
    "ply_target =\"E:/University/Thesis/color_pd30_8bit_small_filtered.ply\"\n",
    "\n",
    "source = o3d.io.read_point_cloud(ply_source)\n",
    "target = o3d.io.read_point_cloud(ply_target)\n",
    "threshold = 0.05\n",
    "voxel_size = 0.1  # means 5cm for the dataset\n",
    "\n",
    "trans_init = np.asarray([\n",
    "    [0.862, 0.011, -0.507, 110.9],\n",
    "    [-0.139, 0.967, -0.215, 220.1],\n",
    "    [0.487, 0.255, 0.835, -1.4],\n",
    "    [0.0, 0.0, 0.0, 1.0]\n",
    "])\n",
    "# trans_init = np.asarray([\n",
    "#     [1, 0, 0, 0],\n",
    "#     [0, 1, 0, 0],\n",
    "#     [0, 0, 1, 0],\n",
    "#     [0, 0, 0, 1]\n",
    "# ])\n",
    "source_down, source_fpfh = preprocess_point_cloud(source, voxel_size)\n",
    "target_down, target_fpfh = preprocess_point_cloud(target, voxel_size)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-04T10:57:25.949154Z",
     "end_time": "2023-05-04T10:57:27.286354Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial alignment\n",
      "RegistrationResult with fitness=0.000000e+00, inlier_rmse=0.000000e+00, and correspondence_set size of 0\n",
      "Access transformation to get result.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Initial alignment\")\n",
    "draw_registration_result(source, target, trans_init)\n",
    "evaluation = o3d.pipelines.registration.evaluate_registration(source, target, threshold, trans_init)\n",
    "print(evaluation)\n",
    "print()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-04T10:57:28.902087Z",
     "end_time": "2023-05-04T10:57:32.900718Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global RegistrationResult with fitness=1.000000e+00, inlier_rmse=1.531789e+00, and correspondence_set size of 6893\n",
      "Access transformation to get result.\n",
      "Global RegistrationResult with fitness=1.710425e-04, inlier_rmse=4.357783e-02, and correspondence_set size of 2\n",
      "Access transformation to get result.\n",
      "Global Transformation\n",
      "[[-9.93376071e-01 -1.14900217e-01 -1.38614232e-03  1.51731754e+02]\n",
      " [ 1.14903958e-01 -9.93372027e-01 -3.01587450e-03  8.96897580e+01]\n",
      " [-1.03043037e-03 -3.15517080e-03  9.99994492e-01  3.39042202e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "source_down = source_down.translate([100, 100, 0], relative=False)\n",
    "source_down_np = np.asarray(source_down.points)\n",
    "source_down = source_down.select_by_index(np.where(source_down_np[:, 2] < 0)[0])\n",
    "voxel_size=5\n",
    "result_fast = execute_global_registration(\n",
    "    source_down,\n",
    "    target_down,\n",
    "    source_fpfh,\n",
    "    target_fpfh,\n",
    "    voxel_size\n",
    ")\n",
    "print(\"Global\", result_fast)\n",
    "draw_registration_result(source_down, target_down, result_fast.transformation)\n",
    "evaluation = o3d.pipelines.registration.evaluate_registration(source, target, threshold, result_fast.transformation)\n",
    "print(\"Global\", evaluation)\n",
    "print(\"Global Transformation\",)\n",
    "print(result_fast.transformation)\n",
    "print()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-04T10:57:34.436886Z",
     "end_time": "2023-05-04T10:58:02.995224Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apply point-to-point ICP\n",
      "RegistrationResult with fitness=5.422893e-01, inlier_rmse=5.878168e-01, and correspondence_set size of 3738\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[-9.92221306e-01 -1.24363189e-01 -5.53861630e-03  1.52827069e+02]\n",
      " [ 1.24163230e-01 -9.91869106e-01  2.79135902e-02  8.84513402e+01]\n",
      " [-8.96500549e-03  2.70087664e-02  9.99594996e-01  5.00113186e-01]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "threshold = 1\n",
    "print(\"Apply point-to-point ICP\")\n",
    "reg_p2p = o3d.pipelines.registration.registration_icp(\n",
    "    source_down,\n",
    "    target_down,\n",
    "    threshold,\n",
    "    result_fast.transformation,\n",
    "    o3d.pipelines.registration.TransformationEstimationPointToPoint()\n",
    ")\n",
    "print(reg_p2p)\n",
    "print(\"Transformation is:\")\n",
    "print(reg_p2p.transformation)\n",
    "print(\"\")\n",
    "draw_registration_result(source, target, reg_p2p.transformation)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-04T10:58:06.209183Z",
     "end_time": "2023-05-04T10:58:13.237869Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apply point-to-plane ICP\n",
      "RegistrationResult with fitness=2.475915e-01, inlier_rmse=3.599910e-01, and correspondence_set size of 60986\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[-0.67361182  0.20082428 -0.71127823  5.85798277]\n",
      " [-0.17337658 -0.97845893 -0.11206557  0.67536355]\n",
      " [-0.71846202  0.0478303   0.69391973  0.26015355]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Apply point-to-plane ICP\")\n",
    "reg_p2l = o3d.pipelines.registration.registration_icp(\n",
    "    source,\n",
    "    target,\n",
    "    threshold,\n",
    "    result_fast.transformation,\n",
    "    o3d.pipelines.registration.TransformationEstimationPointToPlane()\n",
    ")\n",
    "print(reg_p2l)\n",
    "print(\"Transformation is:\")\n",
    "print(reg_p2l.transformation)\n",
    "print(\"\")\n",
    "draw_registration_result(source, target, reg_p2l.transformation)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-02T17:59:56.346192Z",
     "end_time": "2023-05-02T18:00:26.687474Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
