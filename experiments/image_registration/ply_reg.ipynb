{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-05-22T14:30:05.950008Z",
     "end_time": "2023-05-22T14:30:07.329815Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "def draw_registration_result(source, target, transformation=None):\n",
    "    if transformation is None:\n",
    "        transformation = np.asarray([\n",
    "            [1, 0, 0, 0],\n",
    "            [0, 1, 0, 0],\n",
    "            [0, 0, 1, 0],\n",
    "            [0, 0, 0, 1]\n",
    "        ])\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "    target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    source_temp.transform(transformation)\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp])\n",
    "\n",
    "\n",
    "def execute_global_registration(\n",
    "        source_down,\n",
    "        target_down,\n",
    "        source_fpfh,\n",
    "        target_fpfh,\n",
    "        distance_threshold\n",
    "):\n",
    "    result = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(\n",
    "        source=source_down,\n",
    "        target=target_down,\n",
    "        source_feature=source_fpfh,\n",
    "        target_feature=target_fpfh,\n",
    "        mutual_filter=False,\n",
    "        max_correspondence_distance=distance_threshold,\n",
    "        estimation_method=o3d.pipelines.registration.TransformationEstimationPointToPoint(False),\n",
    "        # estimation_method=o3d.pipelines.registration.TransformationEstimationPointToPlane(),\n",
    "        ransac_n=3,\n",
    "        checkers=[\n",
    "            o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(0.9),\n",
    "            o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(distance_threshold)\n",
    "        ],\n",
    "        criteria=o3d.pipelines.registration.RANSACConvergenceCriteria(200000, 0.99999)\n",
    "    )\n",
    "    return result\n",
    "\n",
    "\n",
    "def preprocess_point_cloud(pcd, voxel_size=0):\n",
    "    # pcd_down = pcd.voxel_down_sample(voxel_size)\n",
    "    pcd_down = pcd\n",
    "\n",
    "    radius_ = radius(pcd)\n",
    "    radius_normal = radius_ * 3\n",
    "    radius_feature = radius_ * 20\n",
    "    max_nn = 200\n",
    "    # radius_feature = voxel_size * 5\n",
    "    # radius_normal = voxel_size * 2\n",
    "\n",
    "    pcd_down.estimate_normals(o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=max_nn))\n",
    "    pcd_down.estimate_normals()\n",
    "    pcd_fpfh = o3d.pipelines.registration.compute_fpfh_feature(\n",
    "        pcd_down,\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_feature, max_nn=max_nn))\n",
    "    return pcd_down, pcd_fpfh\n",
    "\n",
    "\n",
    "def show_range_coords(ply):\n",
    "    ply_np = np.asarray(ply.points)\n",
    "    print()\n",
    "    for i in range(3):\n",
    "        print(\n",
    "            ply_np[:, i].min(),\n",
    "            ply_np[:, i].max(),\n",
    "            \"range:\",\n",
    "            ply_np[:, i].max() - ply_np[:, i].min()\n",
    "        )\n",
    "\n",
    "def radius(ply):\n",
    "    distances = ply.compute_nearest_neighbor_distance()\n",
    "    avg_dist = np.mean(distances)\n",
    "    radius = 3 * avg_dist\n",
    "    print(\"radius:\", radius)\n",
    "    return radius"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-22T16:05:00.192119Z",
     "end_time": "2023-05-22T16:05:00.209113Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source\n",
      "\n",
      "-5.18475866317749 5.746166229248047 range: 10.930924892425537\n",
      "-6.182560920715332 3.956705331802368 range: 10.1392662525177\n",
      "-0.5147021412849426 1.6505919694900513 range: 2.165294110774994\n",
      "radius: 0.05778257459745971\n",
      "target\n",
      "\n",
      "-81.13799711305182 85.67450288694818 range: 166.8125\n",
      "-76.10136783309281 68.89863216690719 range: 145.0\n",
      "-11.236785264176717 16.793217329817423 range: 28.03000259399414\n",
      "radius: 2.630230003760081\n",
      "radius: 2.4452413620393094\n"
     ]
    }
   ],
   "source": [
    "# ply_source = \"D:/sfm_dense/street_1_0_real_time/target.ply\"\n",
    "# ply_source = \"D:/sfm_dense/street_2_0/dense/0/color_pd30_8bit_sample.ply\"\n",
    "\n",
    "# ply_target = \"D:/sfm_dense/street_1_0_query/dense/0/fused.ply\"\n",
    "# ply_target = \"D:/sfm_dense/street_1_0_query/query.sparse.ply\"\n",
    "# ply_target =\"E:/University/Thesis/color_pd30_8bit_small_filtered.ply\"\n",
    "\n",
    "# street_4_0\n",
    "# ply_source = \"D:/sfm_dense/street_4_0_1/dense/0/fused_scaled_uniformed.ply\"\n",
    "# ply_target = \"D:/sfm_dense/color_pd30_8bit_street_4_0_sliced_uniformed.ply\"\n",
    "\n",
    "# street_4_3\n",
    "ply_source = \"D:/sfm_dense/street_4_3_3/dense/0/fused_uniformed_aligned.ply\"\n",
    "ply_target = \"D:\\sfm_dense\\street_4_3_3\\color_pd30_8bit_small_street_4_3_3.ply\"\n",
    "\n",
    "\n",
    "source = o3d.io.read_point_cloud(ply_source)\n",
    "target = o3d.io.read_point_cloud(ply_target)\n",
    "\n",
    "# Preprocessing source\n",
    "print(\"source\")\n",
    "scale = 13\n",
    "show_range_coords(source)\n",
    "source = source.voxel_down_sample(voxel_size=radius(source)*1.5)\n",
    "\n",
    "source = source.select_by_index(np.where(np.asarray(source.points)[:, 2] < -.3)[0])\n",
    "source.scale(scale, center=source.get_center())\n",
    "# o3d.visualization.draw_geometries([source, target])\n",
    "\n",
    "\n",
    "# Preprocessing target\n",
    "print(\"target\")\n",
    "show_range_coords(target)\n",
    "target = target.select_by_index(np.where(np.asarray(target.points)[:, 2] < -3)[0])\n",
    "\n",
    "\n",
    "\n",
    "draw_registration_result(source, target)\n",
    "\n",
    "source_down, source_fpfh = preprocess_point_cloud(source)\n",
    "target_down, target_fpfh = preprocess_point_cloud(target)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-22T16:05:01.466856Z",
     "end_time": "2023-05-22T16:05:04.492392Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial alignment\n",
      "radius: 2.630230003760081\n",
      "RegistrationResult with fitness=0.000000e+00, inlier_rmse=0.000000e+00, and correspondence_set size of 0\n",
      "Access transformation to get result.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Initial alignment\")\n",
    "trans_init = np.asarray([\n",
    "    [0.862, 0.011, -0.507, 110.9],\n",
    "    [-0.139, 0.967, -0.215, 220.1],\n",
    "    [0.487, 0.255, 0.835, -1.4],\n",
    "    [0.0, 0.0, 0.0, 1.0]\n",
    "])\n",
    "draw_registration_result(source, target, trans_init)\n",
    "evaluation = o3d.pipelines.registration.evaluate_registration(source, target, radius(source), trans_init)\n",
    "print(evaluation)\n",
    "print()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-22T16:05:04.496394Z",
     "end_time": "2023-05-22T16:05:07.410270Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "radius: 2.6302300037600803\n",
      "Global RegistrationResult with fitness=9.427208e-01, inlier_rmse=1.316531e+00, and correspondence_set size of 1185\n",
      "Access transformation to get result.\n",
      "Global RegistrationResult with fitness=6.483691e-01, inlier_rmse=5.532200e-01, and correspondence_set size of 815\n",
      "Access transformation to get result.\n",
      "Global Transformation\n",
      "[[ 5.38734591e-01 -8.42445905e-01  7.06674185e-03  2.53697368e+01]\n",
      " [ 8.42122165e-01  5.38246747e-01 -3.34768558e-02 -1.48726709e+02]\n",
      " [ 2.43987892e-02  2.39862001e-02  9.99414509e-01 -1.29135057e+01]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "source_down = source_down.translate([100, 100, 0], relative=False)\n",
    "\n",
    "result_fast = execute_global_registration(\n",
    "    source_down,\n",
    "    target_down,\n",
    "    source_fpfh,\n",
    "    target_fpfh,\n",
    "    radius(source)*1.5\n",
    ")\n",
    "print(\"Global\", result_fast)\n",
    "draw_registration_result(source_down, target_down, result_fast.transformation)\n",
    "evaluation = o3d.pipelines.registration.evaluate_registration(source, target, threshold, result_fast.transformation)\n",
    "print(\"Global\", evaluation)\n",
    "print(\"Global Transformation\",)\n",
    "print(result_fast.transformation)\n",
    "print()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-22T16:05:08.752099Z",
     "end_time": "2023-05-22T16:07:02.070048Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apply point-to-point ICP\n",
      "RegistrationResult with fitness=6.626889e-01, inlier_rmse=5.223891e-01, and correspondence_set size of 833\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 5.44446215e-01 -8.38774711e-01  5.94160171e-03  2.47639086e+01]\n",
      " [ 8.38505340e-01  5.44057675e-01 -3.01668849e-02 -1.49167377e+02]\n",
      " [ 2.20706462e-02  2.14063111e-02  9.99527216e-01 -1.26211217e+01]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "threshold = 1\n",
    "print(\"Apply point-to-point ICP\")\n",
    "reg_p2p = o3d.pipelines.registration.registration_icp(\n",
    "    source_down,\n",
    "    target_down,\n",
    "    threshold,\n",
    "    result_fast.transformation,\n",
    "    o3d.pipelines.registration.TransformationEstimationPointToPoint()\n",
    ")\n",
    "print(reg_p2p)\n",
    "print(\"Transformation is:\")\n",
    "print(reg_p2p.transformation)\n",
    "print(\"\")\n",
    "draw_registration_result(source, target, reg_p2p.transformation)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-22T16:07:03.855828Z",
     "end_time": "2023-05-22T16:07:48.654560Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apply point-to-plane ICP\n",
      "RegistrationResult with fitness=6.603023e-01, inlier_rmse=5.096639e-01, and correspondence_set size of 830\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 6.60372333e-01 -7.50935691e-01  1.99245699e-03  3.08888396e+00]\n",
      " [ 7.50631980e-01  6.60024821e-01 -3.03127997e-02 -1.54736644e+02]\n",
      " [ 2.14478921e-02  2.15133362e-02  9.99538476e-01 -1.25494599e+01]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Apply point-to-plane ICP\")\n",
    "reg_p2l = o3d.pipelines.registration.registration_icp(\n",
    "    source,\n",
    "    target,\n",
    "    threshold,\n",
    "    result_fast.transformation,\n",
    "    o3d.pipelines.registration.TransformationEstimationPointToPlane()\n",
    ")\n",
    "print(reg_p2l)\n",
    "print(\"Transformation is:\")\n",
    "print(reg_p2l.transformation)\n",
    "print(\"\")\n",
    "draw_registration_result(source, target, reg_p2l.transformation)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-22T16:07:50.638578Z",
     "end_time": "2023-05-22T16:08:15.646889Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
