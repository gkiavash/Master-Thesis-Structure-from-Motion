{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-05-26T10:49:18.383578Z",
     "end_time": "2023-05-26T10:49:19.145713Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def draw_registration_result(source, target, transformation=None):\n",
    "    if transformation is None:\n",
    "        transformation = np.asarray([\n",
    "            [1, 0, 0, 0],\n",
    "            [0, 1, 0, 0],\n",
    "            [0, 0, 1, 0],\n",
    "            [0, 0, 0, 1]\n",
    "        ])\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "    target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    source_temp.transform(transformation)\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp])\n",
    "\n",
    "\n",
    "def execute_global_registration(\n",
    "        source_down,\n",
    "        target_down,\n",
    "        source_fpfh,\n",
    "        target_fpfh,\n",
    "        distance_threshold\n",
    "):\n",
    "    result = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(\n",
    "        source=source_down,\n",
    "        target=target_down,\n",
    "        source_feature=source_fpfh,\n",
    "        target_feature=target_fpfh,\n",
    "        mutual_filter=False,\n",
    "        max_correspondence_distance=distance_threshold,\n",
    "        estimation_method=o3d.pipelines.registration.TransformationEstimationPointToPoint(False),\n",
    "        # estimation_method=o3d.pipelines.registration.TransformationEstimationPointToPlane(),\n",
    "        ransac_n=3,\n",
    "        checkers=[\n",
    "            o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(0.9),\n",
    "            o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(distance_threshold)\n",
    "        ],\n",
    "        criteria=o3d.pipelines.registration.RANSACConvergenceCriteria(200000, 0.99999)\n",
    "    )\n",
    "    return result\n",
    "\n",
    "\n",
    "def execute_global_registration_corr(source_down, target_down, corres, distance_threshold=None):\n",
    "    if distance_threshold is None:\n",
    "        distance_threshold = radius(source_down) * 1.5\n",
    "\n",
    "    result = o3d.pipelines.registration.registration_ransac_based_on_correspondence(\n",
    "        source_down,\n",
    "        target_down,\n",
    "        corres,\n",
    "        max_correspondence_distance=distance_threshold,\n",
    "        estimation_method=o3d.pipelines.registration.TransformationEstimationPointToPoint(False),\n",
    "        ransac_n=3,\n",
    "        criteria=o3d.pipelines.registration.RANSACConvergenceCriteria(200000, 0.99999)\n",
    "    )\n",
    "    return result\n",
    "\n",
    "\n",
    "def preprocess_point_cloud(pcd, voxel_size=0):\n",
    "    # pcd_down = pcd.voxel_down_sample(voxel_size)\n",
    "    pcd_down = pcd\n",
    "\n",
    "    radius_ = radius(pcd)\n",
    "    radius_normal = radius_ * 3\n",
    "    radius_feature = radius_ * 20\n",
    "    max_nn = 200\n",
    "    # radius_feature = voxel_size * 5\n",
    "    # radius_normal = voxel_size * 2\n",
    "\n",
    "    pcd_down.estimate_normals(o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=max_nn))\n",
    "    pcd_down.estimate_normals()\n",
    "    pcd_fpfh = o3d.pipelines.registration.compute_fpfh_feature(\n",
    "        pcd_down,\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_feature, max_nn=max_nn))\n",
    "    return pcd_down, pcd_fpfh\n",
    "\n",
    "\n",
    "def show_range_coords(ply):\n",
    "    ply_np = np.asarray(ply.points)\n",
    "    print()\n",
    "    for i in range(3):\n",
    "        print(\n",
    "            ply_np[:, i].min(),\n",
    "            ply_np[:, i].max(),\n",
    "            \"range:\",\n",
    "            ply_np[:, i].max() - ply_np[:, i].min()\n",
    "        )\n",
    "\n",
    "\n",
    "def radius(ply):\n",
    "    distances = ply.compute_nearest_neighbor_distance()\n",
    "    avg_dist = np.mean(distances)\n",
    "    radius = 3 * avg_dist\n",
    "    print(\"radius:\", radius)\n",
    "    return radius\n",
    "\n",
    "\n",
    "def get_scale_factor(source, target, corres):\n",
    "    source_np = np.asarray(source.points)\n",
    "    target_np = np.asarray(target.points)\n",
    "\n",
    "    t_d_0 = np.linalg.norm(target_np[corres[0][1]] - target_np[corres[1][1]])\n",
    "    t_d_1 = np.linalg.norm(target_np[corres[1][1]] - target_np[corres[2][1]])\n",
    "\n",
    "    s_d_0 = np.linalg.norm(source_np[corres[0][0]] - source_np[corres[1][0]])\n",
    "    s_d_1 = np.linalg.norm(source_np[corres[1][0]] - source_np[corres[2][0]])\n",
    "    # print(t_d_0, s_d_0, t_d_0/s_d_0)\n",
    "    # print(t_d_1, s_d_1, t_d_1/s_d_1)\n",
    "    scale_ratio_0 = float(t_d_0/s_d_0)\n",
    "    scale_ratio_1 = float(t_d_1/s_d_1)\n",
    "\n",
    "    return sum([scale_ratio_0, scale_ratio_1])/2\n",
    "\n",
    "\n",
    "def slice(ply, threshold, preview=False):\n",
    "    \"\"\"\n",
    "    :param threshold: percentage from z_min\n",
    "    \"\"\"\n",
    "    assert 0 < threshold < 1\n",
    "    ply_np = np.asarray(ply.points)\n",
    "    z_min = ply_np[:, 2].min()\n",
    "    z_max = ply_np[:, 2].max()\n",
    "    z_threshold = (z_max - z_min) * threshold\n",
    "\n",
    "    ply_sliced = ply.select_by_index(np.where(ply_np[:, 2] < z_min + z_threshold)[0])\n",
    "\n",
    "    print(ply)\n",
    "    print(ply_sliced)\n",
    "    print(1, z_min + z_threshold)\n",
    "\n",
    "    if preview:\n",
    "        o3d.visualization.draw_geometries([ply_sliced])\n",
    "    return ply_sliced"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-26T11:00:31.101482Z",
     "end_time": "2023-05-26T11:00:31.136745Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source\n",
      "\n",
      "-5.18475866317749 5.746166229248047 range: 10.930924892425537\n",
      "-6.182560920715332 3.956705331802368 range: 10.1392662525177\n",
      "-0.5147021412849426 1.6505919694900513 range: 2.165294110774994\n",
      "target\n",
      "\n",
      "-81.13799711303918 85.67450288696082 range: 166.8125\n",
      "-76.10136783277241 68.89863216722759 range: 145.0\n",
      "-11.236785264176856 -5.636782975358497 range: 5.6000022888183585\n",
      "radius: 0.6639217821248121\n",
      "radius: 2.891610618263282\n"
     ]
    }
   ],
   "source": [
    "# ply_source = \"D:/sfm_dense/street_1_0_real_time/target.ply\"\n",
    "# ply_source = \"D:/sfm_dense/street_2_0/dense/0/color_pd30_8bit_sample.ply\"\n",
    "\n",
    "# ply_target = \"D:/sfm_dense/street_1_0_query/dense/0/fused.ply\"\n",
    "# ply_target = \"D:/sfm_dense/street_1_0_query/query.sparse.ply\"\n",
    "# ply_target =\"E:/University/Thesis/color_pd30_8bit_small_filtered.ply\"\n",
    "\n",
    "# street_4_0\n",
    "# ply_source = \"D:/sfm_dense/street_4_0_1/dense/0/fused_scaled_uniformed.ply\"\n",
    "# ply_target = \"D:/sfm_dense/color_pd30_8bit_street_4_0_sliced_uniformed.ply\"\n",
    "\n",
    "# street_4_3_2\n",
    "# success\n",
    "# ply_source = \"D:/sfm_dense/street_4_3_2/dense/0/street_4_3_2_fused_ele_uniformed_aligned.ply\"\n",
    "# ply_target = \"D:\\sfm_dense\\street_4_3_2\\street_4_3_2_color_pd30_8bit_small_ele_uniformed_aligned.ply\"\n",
    "\n",
    "# street_4_3_3\n",
    "# success\n",
    "ply_source = \"D:/sfm_dense/street_4_3_3/dense/0/fused_uniformed_aligned.ply\"\n",
    "# ply_target = \"D:\\sfm_dense\\street_4_3_3\\color_pd30_8bit_small_street_4_3_3.ply\"\n",
    "ply_target = \"D:\\sfm_dense\\street_4_3_3\\color_pd30_8bit_small_street_4_3_3_ele_uniformed_sliced.ply\"\n",
    "\n",
    "\n",
    "source = o3d.io.read_point_cloud(ply_source)\n",
    "target = o3d.io.read_point_cloud(ply_target)\n",
    "\n",
    "# Preprocessing source\n",
    "print(\"source\")\n",
    "scale_ = 10\n",
    "scale_ = 11.49  # 4_3_3\n",
    "show_range_coords(source)\n",
    "# source = slice(source, 0.15)  # NO for corres\n",
    "source.scale(scale_, center=source.get_center())\n",
    "# source = source.voxel_down_sample(voxel_size=radius(source)*1.5)  # NO for corres\n",
    "\n",
    "\n",
    "# Preprocessing target\n",
    "print(\"target\")\n",
    "show_range_coords(target)\n",
    "# target = slice(target, 0.5)\n",
    "\n",
    "\n",
    "draw_registration_result(source, target)\n",
    "\n",
    "source_down, source_fpfh = preprocess_point_cloud(source)\n",
    "target_down, target_fpfh = preprocess_point_cloud(target)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-26T11:20:00.179415Z",
     "end_time": "2023-05-26T11:20:03.489997Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "radius: 2.104506917465689\n",
      "Global RegistrationResult with fitness=5.274361e-01, inlier_rmse=1.631254e+00, and correspondence_set size of 1115\n",
      "Access transformation to get result.\n",
      "radius: 2.104506917465689\n",
      "Global RegistrationResult with fitness=5.274361e-01, inlier_rmse=1.631254e+00, and correspondence_set size of 1115\n",
      "Access transformation to get result.\n",
      "Global Transformation\n",
      "[[ 3.94911840e-01 -9.18650236e-01  1.12420199e-02  8.99363575e+01]\n",
      " [-9.18685945e-01 -3.94764224e-01  1.33169915e-02  1.45858695e+02]\n",
      " [-7.79571014e-03 -1.55869233e-02 -9.99848126e-01 -5.91778817e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "source_down = source_down.translate([100, 100, 0], relative=False)\n",
    "\n",
    "result_fast = execute_global_registration(\n",
    "    source_down,\n",
    "    target_down,\n",
    "    source_fpfh,\n",
    "    target_fpfh,\n",
    "    radius(source)*1.5\n",
    ")\n",
    "print(\"Global\", result_fast)\n",
    "draw_registration_result(source_down, target_down, result_fast.transformation)\n",
    "evaluation = o3d.pipelines.registration.evaluate_registration(source, target, radius(source)*1.5, result_fast.transformation)\n",
    "print(\"Global\", evaluation)\n",
    "print(\"Global Transformation\",)\n",
    "print(result_fast.transformation)\n",
    "print()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-26T11:00:35.571883Z",
     "end_time": "2023-05-26T11:00:38.723058Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "radius: 0.6639217821248121\n",
      "Global Corres RegistrationResult with fitness=2.470229e-01, inlier_rmse=5.856566e-01, and correspondence_set size of 7675\n",
      "Access transformation to get result.\n",
      "radius: 0.6639217821248121\n",
      "Global Corres RegistrationResult with fitness=2.470229e-01, inlier_rmse=5.856566e-01, and correspondence_set size of 7675\n",
      "Access transformation to get result.\n",
      "Global Corres Transformation\n",
      "[[-8.28591373e-01 -5.59158000e-01  2.79046348e-02  7.52762634e+00]\n",
      " [ 5.59333007e-01 -8.28941076e-01 -1.81082177e-03 -2.28787170e+01]\n",
      " [ 2.41438335e-02  1.41075520e-02  9.99608950e-01 -4.43274391e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_indexes = [\n",
    "    5572,\n",
    "    4510,\n",
    "    2124,\n",
    "    2624\n",
    "]\n",
    "source_indexes = [\n",
    "    1811,\n",
    "    1984,\n",
    "    9395,\n",
    "    566\n",
    "]\n",
    "corres = o3d.utility.Vector2iVector(list(zip(source_indexes, target_indexes)))\n",
    "result = execute_global_registration_corr(\n",
    "    source_down,\n",
    "    target_down,\n",
    "    corres,\n",
    "    distance_threshold=None\n",
    ")\n",
    "print(\"Global Corres\", result)\n",
    "draw_registration_result(source_down, target_down, result.transformation)\n",
    "evaluation = o3d.pipelines.registration.evaluate_registration(source, target, radius(source)*1.5, result.transformation)\n",
    "print(\"Global Corres\", evaluation)\n",
    "print(\"Global Corres Transformation\",)\n",
    "print(result.transformation)\n",
    "print()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-26T11:20:07.413035Z",
     "end_time": "2023-05-26T11:20:12.466265Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature class with dimension = 33 and num = 31070\n",
      "Access its data via data member.\n",
      "(33, 31070)\n"
     ]
    }
   ],
   "source": [
    "print(source_fpfh)\n",
    "print(source_fpfh.data.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-26T11:27:00.698630Z",
     "end_time": "2023-05-26T11:27:00.712632Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apply point-to-point ICP\n",
      "RegistrationResult with fitness=6.626889e-01, inlier_rmse=5.223891e-01, and correspondence_set size of 833\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 5.44446215e-01 -8.38774711e-01  5.94160171e-03  2.47639086e+01]\n",
      " [ 8.38505340e-01  5.44057675e-01 -3.01668849e-02 -1.49167377e+02]\n",
      " [ 2.20706462e-02  2.14063111e-02  9.99527216e-01 -1.26211217e+01]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "threshold = 1\n",
    "print(\"Apply point-to-point ICP\")\n",
    "reg_p2p = o3d.pipelines.registration.registration_icp(\n",
    "    source_down,\n",
    "    target_down,\n",
    "    threshold,\n",
    "    result_fast.transformation,\n",
    "    o3d.pipelines.registration.TransformationEstimationPointToPoint()\n",
    ")\n",
    "print(reg_p2p)\n",
    "print(\"Transformation is:\")\n",
    "print(reg_p2p.transformation)\n",
    "print(\"\")\n",
    "draw_registration_result(source, target, reg_p2p.transformation)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-22T16:07:03.855828Z",
     "end_time": "2023-05-22T16:07:48.654560Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apply point-to-plane ICP\n",
      "RegistrationResult with fitness=6.603023e-01, inlier_rmse=5.096639e-01, and correspondence_set size of 830\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 6.60372333e-01 -7.50935691e-01  1.99245699e-03  3.08888396e+00]\n",
      " [ 7.50631980e-01  6.60024821e-01 -3.03127997e-02 -1.54736644e+02]\n",
      " [ 2.14478921e-02  2.15133362e-02  9.99538476e-01 -1.25494599e+01]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Apply point-to-plane ICP\")\n",
    "reg_p2l = o3d.pipelines.registration.registration_icp(\n",
    "    source,\n",
    "    target,\n",
    "    threshold,\n",
    "    result_fast.transformation,\n",
    "    o3d.pipelines.registration.TransformationEstimationPointToPlane()\n",
    ")\n",
    "print(reg_p2l)\n",
    "print(\"Transformation is:\")\n",
    "print(reg_p2l.transformation)\n",
    "print(\"\")\n",
    "draw_registration_result(source, target, reg_p2l.transformation)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-22T16:07:50.638578Z",
     "end_time": "2023-05-22T16:08:15.646889Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
