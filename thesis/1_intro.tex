%! Author = ASUS
%! Date = 6/29/2023

% Preamble
\documentclass[11pt]{article}

% Packages
\usepackage{amsmath}

% Document
\begin{document}
    Structure from Motion is the task of calculating the 3D structure of a scene and the pose of cameras from
    a set of 2D images or video frames.
    It is a fundamental tool in many 3D Computer Vision applications such as 3D modeling, augmented reality,
    Robotics and Autonomous Systems.
    Several algorithms have been presented in this area. However, in general, most of them follow the same procedure.
    The incremental Structure from Motion algorithm, \cite{schoenberger2016sfm}, consists of the following major steps.
    For every new image: - Feature detection and matching, i.e. identifying distinctive features and finding the
    correspondings in the previous images - Camera pose estimation using epipolar geometry - 3D point extraction
    by triangulation - and finally Bundle adjustment, i.e. optimizing the camera poses and 3D point positions by
    minimizing the reprojection error. (See Chapter \ref{chap:sfm})

    Since the algorithm is incremental and iterative, without re-observing previously seen landmarks the errors increase for each new input image. Moreover, the reconstruction process may fail and it is no longer possible to record new images, with results that converge to a completely wrong 3D scene. Therefore, the accuracy and robustness of each step of the algorithm are crucial.

    Some of the key challenges in feature matching, which is also a core task in many computer vision tasks,
    include occlusions, repetitive patterns, low-texture regions, and changes in lighting conditions.
    Noise and outliers, like moving objects, also can negatively impact the accuracy
    of the reconstructed 3D scene and camera poses. Moreover, SfM algorithms are computationally intensive,
    making them challenging to deploy in real-time or online applications where speed is crucial.

    Recent papers have shown great improvement in all these challenges. In this thesis, some of the best approaches are
    reviewed and compared. Among these papers, "Pixel-Perfect Structure-from-Motion with Featuremetric Refinement",
    ~\cite{lindenberger2021pixsfm}, has shown a prominent performance. Their method can be added as an extra refinement
    step to the SfM pipeline. In summary, this paper generates
    a feature map per image using Convolutional Neural Networks. Then, the position of the existing keypoints are adjusted by defining a flow
    from one point to another through a gradient descent update and a loss function based on the differences in their
    feature map values.
    Furthermore, in bundle adjustment's reprojection error, this paper considers the difference between the
    feature vectors instead of the typical euclidean distance between the original 2D data points and the reprojected
    3D points (See chapter \ref{chap:sfm}).

    In this thesis, we acquired several datasets from a hand-held camera moving in an urban environment. Our camera is fixed on the head of a vehicle, and several videos are captured from the streets of the city center of padova. The frames of these videos are passed through Structure from Motion pipeline, and then, the results are refined by ~\cite{lindenberger2021pixsfm} paper mentioned above, obtaining very promising 3D reconstructions.
   Next, we will develop an algorithm that localizes the reconstructed point clouds inside a global map of the city. What if the task of localization becomes perfectly offline without any usage of GPS or other online technologies?
    A large-scale dataset of more than 3 million 3D points has already been acquired via an airplane equipped with a LiDAR over the city of Padova,
    covering an area of 1600m by 1000m. After some
    proper preprocessing, our reconstructed  point clouds are registered within the big city point cloud, i.e. the position of our captured point cloud is found in the city. A detailed description of the proposed algorithm can be found in
    chapter \ref{chap:experiment}.

    This thesis is structured as follows:
    \begin{itemize}
        \item In Chapter \ref{chap:background} , the mathematical and geometrical background required for our work are presented, including camera geometry, epipolar geometry
        \item In Chapter \ref{chap:sfm}, the algorithm of Structure from Motion is described in detail, and then, a selection of papers with the best contributions to this field are reviewed; With particular attention to "Pixel-Perfect Structure-from-Motion with Featuremetric Refinement", ~\cite{lindenberger2021pixsfm}
        \item In Chapter \ref{chap:method}, we will use SfM in a real world scenario. We will develop an algorithm for the task of localization using the generated point clouds
        \item In Chapter \ref{chap:experiment}, our dataset, metrics, experiment results, and their discussion are provided
        \item Lastly, in Chapter \ref{chap:conclusion}, the prons and cons of our method are discussed, and a few ideas for future improvements are suggested
    \end{itemize}

\end{document}